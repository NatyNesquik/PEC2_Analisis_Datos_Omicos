---
title: 'PEC2: Análisis Datos Ómicos: https://github.com/NatyNesquik/PEC2_Analisis_Datos_Omicos.git'
author: "Natalia Díaz González"
date: "28/05/2020"
output:
  prettydoc::html_pretty:
    toc: yes
    theme: hpstr
  pdf_document:
    toc: yes
    toc_depth: 3
    fig_caption: yes        
    includes:  
      in_header: my_header.tex
  word_document:
    toc: yes
    toc_depth: '2'
  editor_options:
    chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(fig.pos = "!H", out.extra = "", echo = TRUE, message = FALSE, warning = FALSE, comment = NA, prompt = TRUE, tidy = FALSE, fig.width = 7, fig.height = 7, fig_caption = TRUE,cache=FALSE)
Sys.setlocale("LC_TIME", "C")
```

```{r echo=FALSE}
if(!(require(printr))) {
  install.packages(
    'printr',
    type = 'source',
    repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
  )
}
```

# 1. Introducción y Objetivos

Tras la finalización de las últimas unidades, procedemos a poner en práctica y unificar los conocimientos adquiridos mediante esta PEC cuyo objetivo es ilustrar el proceso de análisis de datos de ultrasecuenciación mediante la realización de un estudio, de principio a fin. Para ello:

- Se partirá de un problema y unos datos seleccionados decidiendo un pipeline de análisis apropiado, con la herramienta que consideréis adecuada (R/Bioconductor o Galaxy) y se realizará el análisis siguiendo las pautas presentadas en los materiales.
- Una vez obtenidos los resultados se procederá a redactar un informe con la estructura tradicional de un informe científico-técnico.

La presentacion de esta práctica se realizará en formato PDF mediante el uso de Markdown.

Los datos y el código para el análisis se pueden localizar mediante el siguiente repositorio de github:

*https://github.com/NatyNesquik/PEC2_Analisis_Datos_Omicos.git*.

## 1.1. Palabras Clave

Ultrasecuenciación, Bioconductor, R, Genes expresados Diferencialmente.

## 1.2. Objetivos

El objetivo de esta PEC es el proceso de análisis de datos de ultrasecuenciación mediante la realización de un estudio, de principio a fin, tal como se llevaría a cabo en una situación real. Las muestras del estudio han sido seleccionadas del repositorio GTEx (Genotype-Tissue Expression). GTEx es un proyecto continuado para construir un recurso público integral para estudiar la expresión y regulación de genes específicos de tejidos.

*<https://www.gtexportal.org/home/>*  

Para nuestro análisis se recolectaron muestras de 54 sitios de tejidos no enfermos en casi 1000 individuos, principalmente para ensayos moleculares que incluyen el caso que nos compete en esta PEC, RNA-Seq. Las muestras restantes están disponibles en el Biobanco GTEx. El portal GTEx proporciona acceso abierto a datos que incluyen expresión génica, QTL e imágenes histológicas.

El estudio se centra en los datos de expresión (RNA-seq) pertenecientes a un análisis del tiroides en donde se compara tres tipos de infiltración medido en un total de 292
muestras:

• Tejidos no infiltrados (NIT): 236 muestras
• Infiltrados focales pequeños (SFI): 42 muestras
• Infiltrados linfoides extensos (ELI): 14 muestras.

El objetivo de nuestro análisis es encontrar genes diferencialmente expresados entre las 292 individuos que fueron sometidos a estos tres tipos de infiltración.

# 2. Materiales y Métodos

## 2.1. Métodos

Para llevar a cabo el análisis de datos de ultrasecuenciación debemos proceder de forma ordenada y siguiendo el método científico. Este análisis puede ser fácilmente visualizado como un proceso que empieza por una pregunta biológica y concluye con una interpretación de los resultados de los análisis que, de alguna forma nos acerque un poco a la respuesta de la pregunta inicial. 

![Analisis_Ultrasecuenciacion](C:/Users/Naty/Documents/Master/datos_omicos/PEC2/Analisis_ultrasecuenciacion.jpg "Imagen Proceso Analisis Ultrasecuenciacion")

La actual PEC tiene como objetivo realizar un análisis de Ultrasecuenciación de unas muestras dadas. Dichas muestras se obtuvieron por medio del método de secuenciación de ARN denominado RNA Sequencing (RNA-Seq), una de las tecnologías que utiliza la ultrasecuenciación para detectar y cuantificar la cantidad de ADN de un genoma. 

El primer paso que sigue esta técnica es la fragmentación del ADN en pequeños trozos, llamados reads o lecturas que luego se secuencian y finalmente se alinean frente a un genoma de referencia estándar.

Para la expresión genética, un gen poseerá una mayor expresión que otro si el número de reads alineados contra ese gen es mayor.

De esta alineación obtenemos unos datos de conteo, los cuales se resumirán en tablas para su estudio estadístico. Una vez recogidos los datos y resumidos en tablas de conteos, se pueden realizar diversos estudios. El objetivo de nuestro estudio es identificar los genes que son diferencialmente expresados (DE).

Acorde con lo comentado, el flujo de trabajo con RNA-seq sigue los siguientes pasos: 
    
1. Diseño experimental.
2. Protocolos de extracción del RNA.
3. Preparación de las librerías. Se convierte el RNA en cDNA y se añaden los adaptadores para la secuenciación.
4. Se secuencian las lecturas cDNA utilizando una plataforma de secuenciación.
5. Alineamiento de las lecturas secuenciadas a un genoma de referencia.
6. Resumen del número de lecturas alineadas a una región.
7. Normalización de las muestras para eliminar diferencias técnicas en la preparación.
8. Estudio estadístico de la expresión diferencial incluyendo un modelo.

![Analisis_Ultrasecuenciacion](C:/Users/Naty/Documents/Master/datos_omicos/PEC2/pasos_analisis.jpg "Imagen Proceso Analisis Ultrasecuenciacion")

En nuestro caso, nuestro trabajo empieza a partir del momento en que tenemos los conteos y estamos interesados en saber si se expresan diferencialmente entre distintas condiciones biológicas. Para realizar este punto y disponer de un análisis de Ultrasecuenciación debemos seguir los siguientes pasos:

1. __Lectura de los Datos__

2. __Preprocesado__:

    * Exploración y visualización
    * Filtrado de Genes con Baja Expresión
    * Control de Calidad
    * Normalización

3. __Selección de genes expresados diferencialmente__:
    * Análisis de Modelos Lineales: matriz de Diseño y de Contrastes
    * Conversión de los Recuentos para modelos lineales
    * Estimación del modelo y selección de genes expresados diferencialmente

4. __Post-Procesado__:
    * Comparaciones
    * Visualización y Exploración 
    * Anotaciones
    * Análisis de significación biólogica

Para realizar el **preprocesado** de los datos se nos proporcionaron dos archivos csv obtenidos del repositorio GTEx: targets.csv y counts.csv. El preprocesado a realizar establecería un previo paso de filtrado a través del cual eliminaremos aquellos genes que apenas varían entre condiciones o que deseamos quitar. Esto se consigue quedándonos solo con aquellos genes que están representados en lecturas de al menos 1cpm en al menos dos muestras 

Una vez obtenidos los datos filtrados, procedemos a la realización de la **normalización** que permite disponer de:

--> Corrección de fondo eliminando la variabilidad en las muestras que no se deba a razones biológicas
--> Normalización para hacer los valores comparables

El método que vamos a emplear para realizar la normalización es el denominado "trimmed mean of M-values" (TMM) ó media ajustada de valores M, mediante el cual conseguiremos ajustar y corregir la composición del RNA para evitar la aparición de genes infraregulados en aquellas muestras donde solo unos pocos se expresan mucho y consumen una parte fundamental de las lecturas de la librería.

Para efectuar la **selección de genes diferencialmente expresados** debemos realizar una serie de pruebas, generalmente en términos de genes, para comparar la expresión de genes entre grupos. En nuestro caso, se aplicará la aproximación basada en la utilización del modelo lineal general, es decir, se trata de ajustar un modelo lineal a cada gen para detectar diferencias de expresión mediante la librería limma(). El método implementado en limma amplía el análisis tradicional utilizando modelos de Bayes empíricos para combinar la información de toda la matriz de datos y de cada gen individual y obtener estimaciones de error mejoradas. El análisis proporciona los estadísticos de test habituales como Fold-change t-moderados o p-valores ajustados, que se utilizan para ordenar los genes de más a menos diferencialmente expresados

Se realizará un ajuste de p-valores a 0.05 entre las comparaciones invocando al ajuste FDR (False discovery rate) para múltiples contrastes, es decir, se realizará un ajuste de la proporción esperada de hipótesis nulas que son verdaderas entre las que son declaradas como significativas y han sido rechazadas erróneamente.

Una vez identificados los genes expresados diferencialmente, trataremos de agrupar los mismos para localizar posibles patrones comunes entre las condiciones experimentales. Para ello, nos apoyaremos, como se hará a lo largo de todo el análisis, de gráficas que nos ayuden a visualizar dichas agrupaciones: diagrama de Venn, Volcano Plots, mapas de calor, dendogramas...

En el proceso de **“anotación”** buscaremos información para asociar los identificadores correspondientes a códigos Ensembl de los datos de Expresión de tejido genotipo (GTEx) con nombres más familiares como el Identificador del gen Entrez o la descripción del gen.

Para finalizar el análisis, se realizará un **Análisis de Significación Biológica** que busca establecer si, dada una lista de genes seleccionados por ser diferencialmente expresada entre dos condiciones, las funciones, procesos biológicos o vías moleculares que los caracterizan, aparecen en esta lista con más frecuencia que entre el resto de los genes analizados.

## 2.2. Herramientas Bioinformáticas

Para la realización del análisis de datos de ultrasecuenciación hemos empleado las facilidades que ofrecen R Studio y las librerías de Bioconductor. Para el correcto funcionamiento del análisis debemos aseguramos que disponemos de las versiones compatibles en ambos casos. En el caso que nos compete, la versión de R Studio es la 3.4.0.0 y la versión de Bioconductor corresponde a la 3.10.

### 2.2.1. Instalación de Paquetes en R

Para poder realizar el análisis, debemos asegurarnos que disponemos de todos los paquetes necesarios que descargaremos del repositorio CRAN en el caso de paquetes estándar o Bioconductor para paquetes Bioconductor. Cargaremos las librerías necesarias para llevar a cabo el análisis por medio del siguiente código:

```{r echo=FALSE, message=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(Biobase)
library(RColorBrewer)
library(edgeR)
library(tidyverse)
library(DESeq2)
library(gplots)
library(limma)
library(prettyGraphs)
library(Glimma)
library(org.Hs.eg.db)
library(grex)
library("AnnotationDbi")
```

# 3. Datos 

Los datos del estudio han sido proporcionados junto con el enunciado del trabajo para la realización del análisis. Para ello, se nos han facilitado dos archivos nombrados como targets.csv y counts.csv que contienen la información de las muestras de un estudio obtenido del repositorio (GTEx1). Este repositorio contiene datos de múltiples tipos en un total de 54 tejidos. En nuestro caso nos centraremos en los datos de expresión (RNA-seq) pertenecientes a un análisis del tiroides en donde se compara tres tipos de infiltración medido en un total de 292 muestras pertenecientes a tres grupos:

• Tejidos no infiltrados (NIT): 236 muestras.
• Infiltrados focales pequeños (SFI): 42 muestras.
• Infiltrados linfoides extensos (ELI): 14 muestras.

*<https://www.gtexportal.org/home/documentationPage>*

## 3.1. Directorios y opciones de trabajo

Para facilitar nuestro estudio trabajaremos en el directorio ("C:/Users/Natalia/Master/Datos_omicos_2/PEC2") que asignaremos a la variable workingDir. Copiaremos los datos preprocesados en un subdirectorio del anterior denominado data, que se almacenará en la variable dataDir y los resultados los guardaremos en un directorio “results” que asignaremos a la variable resultsDir.

```{r}
setwd("~/Master/datos_omicos/PEC2")
workingDir <-getwd()
dir.create("data")
dir.create("results")
dataDir <-file.path(workingDir, "data")
resultsDir <- file.path(workingDir, "results")
setwd(workingDir)
options(width=80)
options(digits=5)
```

## 3.2. Preparación de los datos para el Análisis

Para efectuar el análisis se nos pide que, a partir de unos datos preprocesados en una tabla de contajes, seleccionemos 30 muestras aleatoriamente, 10 de cada grupo.
Para ello disponemos de dos tipos de archivos:

* "targets.csv" mediante el cual extraeremos 10 muestras del grupo 1 (NIT), 10 del grupo 2 (SFI) y 10 del grupo 3 (ELI) de la columna “Groups”. 
* "counts.csv" a través del cual “subsetearemos” las columnas escogidas en dicho archivo con la información de las filas escogidas en el apartado anterior.  

En primer lugar leeremos ambos archivos en nuestra plataforma:

```{r}
library(readr)
targets <- read_csv("~/Master/datos_omicos/PEC2/data/targets.csv", col_types = cols(Grupo_analisis = col_integer()))
head(targets)
```

```{r}
dim(targets)
```

Se confirma que el archivo target contiene las 292 muestras tal y como se indicó en el enunciado.

```{r}
library(readxl)
counts <- read.csv2("~/Master/datos_omicos/PEC2/data/counts.csv", sep = ";")
dim(counts)
```

El archivo counts presenta 56.202 genes.

```{r}
counts[1:5,1:3]
```

La columna Sample_Name nos muestra el nombre de las muestras en Ensembl. Sin embargo, es necesario darle el formato correcto para evitar problemas futuros en la parte de Anotaciones. Por ello, modificaremos el nombre de los genes borrando el punto y lo que le sigue después del código para que posteriormente pueda ser leído.

```{r}
counts <- dplyr::mutate_if(counts,
                           is.character,
                           stringr::str_replace_all, pattern = "\\..*", replacement = "")
counts[1:5,1:3]
```

Como para nuestro estudio se nos solicita la selección de 30 muestras aleatorias, 10 de cada uno de los 3 grupos, en primer lugar generaré 3 dataframes, uno por cada uno de los tipos de infiltración que contengan las muestras correspondientes:

```{r}
library(dplyr)
NIT_total = filter(targets, targets$Group=="NIT")
SFI_total = filter(targets, targets$Group=="SFI")
ELI_total = filter(targets, targets$Group=="ELI")
```

Una vez disponemos de los mismos, procedemos a extraer 10 muestras aleatorias de cada uno empleando el siguiente código:

```{r}
n<-10
muestra_NIT <- sample(1:nrow(NIT_total),size=n,replace=FALSE)
muestra_SFI <- sample(1:nrow(SFI_total),size=n,replace=FALSE)
muestra_ELI <- sample(1:nrow(ELI_total),size=n,replace=FALSE)
```

```{r}
NIT<- NIT_total[muestra_NIT, ]
SFI<- SFI_total[muestra_SFI, ]
ELI<- ELI_total[muestra_ELI, ]
```

Una vez disponemos de nuestros 3 Dataframe con nuestras 10 muestras aleatorias de cada grupo, lo uniremos en único Dataframe al que denominaremos targets_muestras, que contendrá las 30 muestras aleatorias:

```{r}
targets_muestras <- rbind(NIT, SFI, ELI)
dim(targets_muestras)
```

Una vez disponemos de nuestro Dataframe único, procederemos a subsetear las filas escogidas con las columnas escogidas del archivo "counts". Para ello, extraeremos el nombre de cada una de las muestras que se encuentran localizadas en las filas de nuestro archivo targets_muestras.

```{r}
Sample_Name = targets_muestras$Sample_Name
Sample_Name
```

Como en el dataframe de Counts los nombres de las variables presentan puntos lo que hace que difieran de las muestras reflejadas en el archivo targets_muestras que contienen guiones, debemos reemplazar los "." por "-" para que tengan el mismo formato para poder subsetear las filas de targets con las columnas de counts. Esto lo realizaremos mediante la función gsub:

```{r}
colnew <- function(x){ colnames(x) <- gsub("\\.", "-", colnames(x)); x } 
counts_new <- colnew(counts)
head(counts_new)
```

Seleccionamos las 30 muestras correspondientes del archivo counts:

```{r}
library(dplyr)
muestras <- colnames(counts[1])
selectCols <- c(muestras,Sample_Name)
counts_muestras <- counts_new[,selectCols]
counts_muestras[1:10, 1:4]
```

```{r}
dim(counts_muestras)
```

Como podemos comprobar disponemos de una transcripción génica de 56.202 genes para cada una de las 30 muestras. En el archivo de conteo observamos que se agrega el número de lecturas que se alinean con cada gen anotado. Por ejemplo, se pueden observar muestras en el gen localizado en alguna de las posiciones tiene aproximadamente el doble de lecturas alineadas que el gen localizado en otras posiciones. Esto puede significar que: 

* el gen se expresa con el doble de transcripciones que en otros genes.
* o que ambos genes se expresan con el mismo número de transcripciones, pero uno de los genes es dos veces más largo que el otro gen y produce el doble de fragmentos. En el mismo nivel de expresión, una transcripción larga tendrá más lecturas que una transcripción más corta. 

Para poder efectuar nuestro posterior análisis, generaremos una matriz a raíz del dataframe counts_muestras. Para ello, emplearé una función que nos permitirá mantener todos los valores, así como el nombre de las filas y columnas.

```{r}
matrix.please<-function(x) {
    m<-as.matrix(x[,-1])
    rownames(m)<-x[,1]
    m
}
counts_matrix <- matrix.please(counts_muestras)
counts_matrix[1:10, 1:4]
```

En esta matriz de conteo, cada fila representa un gen Ensembl, cada columna una librería de ARN secuenciada, y los valores dan los números brutos de fragmentos que se asignaron de forma única al gen respectivo en cada librería. También tenemos información sobre cada una de las muestras donde las columnas de la matriz de recuento correspondan a las filas de la tabla de información de muestra.

# 4. Preprocesado: Exploración, Control de Calidad y Normalización

El preprocesado de los datos comprende diferentes fases:

* Realización de algunos gráficos con los datos en crudo para hacerse una idea del experimento.
* Filtrado para eliminar aquellos genes que hemos detectado en las fases anteriores que no se expresan o se expresan de diferente manera que el resto de los grupos y que  consideramos que no deben tenerse en cuenta
* Realizar un control de calidad
* Normalizar y resumir las expresiones

## 4.1. Exploración y Visualización

Para llevar a cabo una primera exploración de la distribución de los datos originales sin filtrar generaremos un **histograma**. Además, nos permitirá hacernos una idea de si la distribución de los genes de las muestras son similares en forma y posición. Obtendremos la distribución del logaritmo en base 2.

```{r}
library(RColorBrewer)
samplenames <- colnames(counts_matrix) 
nsamples <- ncol(counts_matrix)
col <- brewer.pal(nsamples, "Paired")
```

```{r , message=FALSE, fig.align='center', fig.cap="Distrubución del logaritmo en base 2 del recuento para cada gen"}
library(edgeR)
lcpm <- cpm(counts_matrix, log=TRUE)
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,1), las=2,
main="", xlab="")
title(main="A. Raw data", xlab="Log-cpm")
abline(v=0, lty=3)
for (i in 2:nsamples){
den <- density(lcpm[,i])
lines(den$x, den$y, col=col[i], lwd=2)
}
legend (x="topright", legend=samplenames , text.col=col, lty=1:nsamples,cex=0.6,text.font=4, bty="n")
```

Atendiendo al histograma y acorde con lo expuesto, filtraremos los genes con un recuento bruto de 0 en las muestras, así como los genes de baja expresión. La regla que vamos a utilizar en este análisis pipleline es mantener solo los genes que tienen cpm> 1 en al menos 2 muestras.

## 4.2. Filtrado de Genes con Baja Expresión

Una vez disponemos de nuestra matriz de conteo y la tabla de nuestras 30 muestras seleccionadas, procederemos a comenzar el análisis. Tal y como se indicó en el apartado anterior, existían 56.202 genes. Sin embargo, muchos de ellos no se expresarán o no se representarán con suficientes lecturas para contribuir al análisis. Por lo que procederemos a eliminar aquellos genes que muestren una baja expresión génica. Para realizar este filtrado, nos quedaremos solo con aquellos genes que están representados en lecturas de al menos 1cpm en al menos dos muestras (cpm = conteos por millón). Se filtra con cpm en lugar de filtrar directamente los recuentos, ya que este último no tiene en cuenta las diferencias en los tamaños de librerías entre muestras.

```{r}
nrow(counts_matrix)
```

Para calcular los valores de conteos por millón emplearemos la función cpm() de la libería edgeR y luego filtraremos. Mostraremos los valores de las 10 primeras muestras y de las 4 primeras columnas.

```{r}
library(edgeR)
cpm <- cpm(counts_matrix)
cpm[1:10, 1:4]
```

A continuación calcularemos qué valores son superiores a 1cpm en al menos 2 muestras.Esto produce una matriz lógica con Verdaderos y Falsos que llamaremos thresh y generaremos la suma de cuantos valores "Verdaderos" obtendremos de cada fila.  

```{r}
thresh <- cpm > 1
table(rowSums(thresh))
```

Como se indicó al inicio del apartado, mantendremos aquellos genes que tengan al menos 2 Verdaderos en cada fila de la matriz tresh generada, es decir, se filtran un mínimo de 2 muestras sin baja expresión.

```{r}
keep <- rowSums(thresh) >= 2
```

Finalmente, generaremos un subconjunto de datos que contiene los genes más altamente expresados.

```{r}
counts_keep <- counts_matrix[keep,]
counts_keep[1:10, 1:4]
```

De tal manera que, de un inicio partíamos de un conjunto de genes de 56.202 y con el filtrado realizado:

```{r}
nrow(counts_keep)
```

```{r, echo=FALSE}
cat("Se comprueba que el Objeto dispone de un total de:" , nrow(counts_keep),"genes")
```

Para poder visualizar mejor los resultados, comparándolo con los datos originales sin filtrar, vamos a proceder a generar de nuevo el **histograma** pero esta vez con los datos filtrados. Obtendremos la distribución del logaritmo en base 2.

```{r ,  message=FALSE, fig.align='center', fig.cap="Distrubución del logaritmo en base 2 del recuento para cada gen tras el filtrado"}
lcpm <- cpm(counts_keep, log=TRUE)
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.21), las=2,
main="", xlab="")
title(main="B. Datos Filtrados", xlab="Log-cpm")
abline(v=0, lty=3)
for (i in 2:nsamples){
den <- density(lcpm[,i])
lines(den$x, den$y, col=col[i], lwd=2)
}
legend (x="topright", legend=samplenames , text.col=col, lty=1:nsamples,cex=0.6,text.font=4, bty="n")
```

Revisando el resultado del gráfico podemos concluir que nuestro umbral de 1CPM corresponde a un recuentro de 5-15. Si el recuento fuera menor se considera muy bajo, lo que indica que el gen asociado no se expresa en esa muestra. 

### 4.2.1. Construcción del Objeto Final

Una vez filtrados los datos, debemos asegurarnos de que el objeto contenga toda la información necesaria sobre las muestras, es decir, una tabla con metadatos en las columnas de la matriz de conteo.

Para facilitar este paso, generaremos un Dataframe de targets_muestras solo con las columnas que nos interesan, Sample_Name, Group y Sex, y lo denominaremos coldata:

```{r}
coldata <- targets_muestras[,c("Sample_Name","Group", "sex")]
coldata$Sample_Name <- factor(coldata$Sample_Name)
coldata$Group <- factor(coldata$Group)
coldata$sex <- factor(coldata$sex)
```

Examinaremos la matriz de conteo y los datos de la columna para ver si son consistentes en términos de orden de la muestra.

```{r}
counts_keep[1:5, 1:4]
```

```{r}
coldata[1:10,]
```

Para poder combinar la matriz de recuento y nuestro Dataframe, el Nombre de la muestra debe presentarse en colnames en la matriz y en rownames en el dataframe de targets, por lo tanto, usaremos el paquete tidyverse para disponer de este último:

```{r}
library(tidyverse)
coldata <- coldata %>% remove_rownames %>% column_to_rownames(var="Sample_Name")
```

Las columnas de la matriz de conteo y las filas de las muestras de la columna deben estar en el mismo orden ya que DESeq2 no macheará el orden de las mismas. 

```{r}
rownames(coldata)
```

Comprobaremos que los nombres de las muestras de las columnas de la matriz counts_keep vs los nombres de las muestras de las filas de coldata son similares y se encuentran en el mismo orden:

```{r}
all(rownames(coldata) %in% colnames(counts_keep))
```

```{r}
all(rownames(coldata) == colnames(counts_keep))
```

como se comprueba que las muestras de filas y columnas se encuentran en el mismo orden, procederemos a construir el DataSeqDataSet que es una clase de objeto utilizada por el paquete DESeq2 para almacenar los recuentos de lectura y las cantidades estimadas intermedias durante el análisis estadístico:

```{r}
library(DESeq2)
dds <- DESeqDataSetFromMatrix(countData = counts_keep,
                              colData = coldata,
                              design= ~ Group + sex)
```

```{r}
dds[1:10, 1:4]
```

```{r}
dim(dds)
```

```{r, echo=FALSE}
cat("Se comprueba que el Objeto dispone de un total de:" , nrow(dds),"genes en las 30 muestras")
```
    
### 4.2.2. Conversión de counts a Objeto DGEList

Otra forma de almacenar datos de conteo es mediante la creación de un objeto DGEList incluido dentro de la libería edgeR.

```{r}
dgeObj <- DGEList(counts=counts_keep, samples=coldata)
dgeObj[1:10, 1:4]
```

Visualizamos que se han creado dos slots almacenados en el objeto generado:

```{r}
names(dgeObj)
```

La información del tamaño de la librería se almacena en el slot de muestras

```{r}
dgeObj$samples
```

Para continuar con mi análisis utilizaré el objeto dgeObj.

## 4.3. Control de Calidad

Una vez eliminados los genes poco expresados y tenemos nuestros recuentos almacenados en un objeto DGEList, podemos ver en detalle a través de diferentes gráficas si los datos son de buena calidad y que las muestras sean las esperadas. El control de calidad se puede realizar en dos pasos. En el primero se trata de evaluar si tenemos librerías (muestras) con bajas profundidades, o con problemas de calidad o con frecuencias de nucleóticos no frecuentes. En un segundo paso, a nivel de gen, buscamos etiquetas equivocadas asociadas a las muestras, problemas con las distribuciones de probabilidad supuesta (sobredispersión es el gran problema) y sesgos en los contenidos GC.

Tenemos que considerar el número de lecturas alieanadas y no alineadas. Si hay un total
de pocas lecturas esto se atribuye a la mala calidad del RNA. Si hay una tasa de alineamiento bajo es que las lecturas tienen poca calidad, normalmente tienen secuencias poco complejas de difícil alineamiento. También podemos tener un mal genoma de referencia o simplemente mal etiquetadas las muestras.

### 4.3.1. Tamaño de la librería

Verificaremos cuántas lecturas tenemos para cada muestra en dgeObj por medio de la siguiente sentencia:

```{r}
dgeObj$samples$lib.size
```

Para verificar si hay discrepancias entre muestras en el tamaño de la liberías, podemos visualizarlo de manera sencilla por medio de un diagrama de barras:

```{r , message=FALSE, fig.align='center', fig.cap="Gráfico de barras que nos muestra el tamaño de las librerías"}
barplot(dgeObj$samples$lib.size, names=colnames(dgeObj), las=2)
title("Gráfico de barras del tamaño de las liberías")
```

Podemos visualizar la gráfica anterior en relación a los 3 tipos de infiltración:

```{r ,  message=FALSE, fig.align='center', fig.cap="Gráfico de barras que muestra el tamaño de las librerías por cada grupo de infiltración"}
barplot(dgeObj$samples$lib.size, names=dgeObj$samples$Group, las=2)
title("Gráfico de barras del tamaño de las liberías")
```

Los datos de recuento no se distribuyen normalmente, por lo que utilizaremos un **diagrama de cajas** para verificar la distribución de los recuentos de lectura en la escala log2 en base al tamaño de la librería. Usaré la función cpm para obtener recuentos de log2 por millón, para corregir los tamaños de librería. Para visualizar mejor la distribución, marcaré con una línea roja la mediana.

```{r ,  message=FALSE, fig.align='center', fig.cap="Diagrama de Cajas para la distribución de los recuentos de las lecturas con Datos sin Normalizar"}
logcounts <- cpm(dgeObj,log=TRUE)
boxplot(logcounts, xlab="", ylab="Log2 cpm",las=2)
abline(h=median(logcounts),col="red")
title("Boxplots de log2CPM sin Normalizar")
```

Como conclusión de la gráfica anterior, podemos decir que la distribución es bastante similiar. No se observa ninguna muestra que esté muy por encima ni muy por debajo de la línea roja.

### 4.3.2. Análisis del escalamiento multidimensional

En este apartado procederemos a la creación del análisis de componentes principales mediante el cual se comprobará si las variaciones de los datos provienen del tipo de infiltración realizado. Al mismo tiempo, mediante el uso de MDS podremos revisar la existencia de valores atípicos.

```{r , message=FALSE, fig.align='center', fig.cap="Análisis de Componentes Principales por Tipos de Infiltración"}
col.Group <-c("green","purple","orange")[dgeObj$samples$Group]
plotMDS(dgeObj,col=col.Group, cex=0.5)
legend("topleft",fill=c("green","purple","orange"),legend=levels(dgeObj$samples$Group),cex=0.8)
title("Tipo de Infiltración")
```

Se puede observar mediante el gráfico anterior que existe una tendencia a la agrupación de las muestras en base al tipo de infiltración empleado en el experimento. Los NIT en la parte izquierda con valores por debajo de 0 para dim 1, los SFI en el centro y los ELI en la parte derecha con valores superiores a 0 en dim 1

Realizaremos la misma operativa comprobando las variaciones en relación al sexo de los individuos.

```{r , message=FALSE, fig.align='center', fig.cap="Análisis de Componentes Principales por Sexo"}
col.sex <-c("green","red")[dgeObj$samples$sex]
plotMDS(dgeObj,col=col.sex, cex=0.5)
legend("topleft",fill=c("green","red"),legend=levels(dgeObj$samples$sex),cex=0.8)
title("Sexo")
```

En relación al sexo, existe una tendencia a la distribución de las mujeres en valores por encima de 0 de logFC dim2 y por debajo de 0 en los hombres.

Otra forma de poder explorar interactivamente las diferentes dimensiones es a través de un diagrama interactivo MDS utilizando el paquete Glimma()

```{r}
library(Glimma)
labels <- paste(rownames(dgeObj$samples))
group <- paste(dgeObj$samples$Group,sep=".")
group <- factor(group)
glMDSPlot(dgeObj, labels=labels, groups=group, folder="./results/mds")
```

La salida de glMDSPlot es una página html (/mds/MDS-Plot.html) que muestra el diagrama MDS (escalamiento multidimensional) a la izquierda y la cantidad de variación explicada por cada dimensión en un diagrama de barras a la derecha. El usuario puede desplazarse sobre puntos para encontrar información de muestra y cambiar entre dimensiones sucesivas en el diagrama MDS haciendo clic en las barras en el diagrama de barras. Los gráficos MDS predeterminados muestran las dimensiones 1 y 2.

### 4.3.3. Mapa de Calor

Emplearemos los mapas de calor para poder examinar la agrupación jerárquica de las muestras. Los heatmaps permiten representar una matriz de genes en la que, en lugar de números, se muestra un gradiente de color proporcional al valor de cada gen en cada una de las muestras. Al mismo tiempo, incluiremos un dendrograma junto con el mapa de calor que nos permitirá ordenar por semejanza las muestras y los genes de la matriz, a la vez que se muestra con un código de colores el valor de las variables. 

Para tener una visión más fácil de la agrupación, seleccionaremos los 500 genes más variables:

```{r}
var_genes <- apply(logcounts, 1, var)
head(var_genes)
select_var <- names(sort(var_genes, decreasing=TRUE))[1:500]
head(select_var)
highly_variable_lcpm <- logcounts[select_var,]
dim(highly_variable_lcpm)
highly_variable_lcpm[1:10,1:4]
```

Una vez seleccionados los 500 genes, procederemos a dibujar la gráfica. Para una mejor visualización, aplicaremos esquemas de color mejorados y generaremos el mapa de calor a través de la función heatmap.2() que calcula la matriz de distancias euclidianas, es decir la longitud del segmento desde el logCPM para los 500 genes más variables. Gracias a este cluster jerárquico y el dendograma generado podemos hacernos una idea de si las muestras se agrupan por condiciones experimentales.

```{r message=FALSE, fig.align='center', fig.cap="Mapa de Calor de los 500 genes con mayor variabilidad"}
library(gplots)
mypalette <- brewer.pal(11,"Spectral")
morecols <- colorRampPalette(mypalette)
col.group <- c("green","purple","orange")[dgeObj$samples$Group]
heatmap.2(highly_variable_lcpm,
          col=rev(morecols(50)),
          trace="column", 
          main="500 genes más variables",
          ColSideColors=col.group,scale="row")
```

Como podemos visualizar en el gráfico generado puede intuir una tendencia de agrupación de genes entre los 3 grupos diferentes de tipo de infiltración, sin embargo, para mejorar los mismos, es necesario aplicar un proceso de normalización a los datos.

## 4.4. Normalización

Los datos de RNA-seq tienen menos ruido que los datos de microarrays, sin embargo, en el protocolo de preparación intervienen muchos procedimientos que introducen variabilidad: la extracción del RNA, la transcripción reversa, la amplificación y la fragmentacion.

Las covariables de genes y muestras que pueden influir en los conteos y pueden generar ruido técnico son:

* Tamaño de la librería
* Composición del RNA.
* Contenido GC
* Longitud del gen

Con el proceso de normalización vamos intentar que las matrices sean comparables entre ellas y tratar de reducir o eliminar la variabilidad en las muestras que no se deba a razones biológicas. El método que vamos a emplear para realizar la normalización es el denominado "trimmed mean of M-values" (TMM) ó media ajustada de valores M que aplicaremos mediante el paquete edgeR. Mediante este método conseguiremos ajustar y corregir la composición del RNA para evitar la aparición de genes infraregulados en aquellas muestras donde solo unos pocos se expresan mucho y consumen una parte fundamental de la librería de lecturas.

Para realizar la normalización de los datos, emplearemos la función calcNormFactors() en edgeR que calcula los factores de normalización para cada una de las 30 muestras.

```{r}
dgeObj <- calcNormFactors(dgeObj)
dgeObj$samples
```

Un factor de normalización por debajo de uno indica que el tamaño de la librería se reducirá, ya que hay más sesgo de composición en esa librería en relación con las otras y se incrementarán los recuentos en esa muestra. Por el contrario, un factor superior a uno aumenta el tamaño de la librería y conllevaría a reducir los recuentos. Detectamos que las muestras 24 y 15 son las que tienen mayores factores de normalización.

Generaremos una gráfica empleando los registros que se han normalizado para mostrar la diferencia de medias usando la función plotMD() para estas muestras. Mediante esta gráfica podemos detectar los sesgo de composición así como su correción. Mostraremos las gráficas de las 8 primeras muestras:

```{r ,message=FALSE, fig.align='center', fig.cap="Diferencia de medias de las 8 primeras muestras"}
par(mfrow=c(2,4))
plotMD(dgeObj,column = 1)
abline(h=0,col="grey")
plotMD(dgeObj,column = 2)
abline(h=0,col="grey")
plotMD(dgeObj,column = 3)
abline(h=0,col="grey")
plotMD(dgeObj,column = 4)
abline(h=0,col="grey")
plotMD(dgeObj,column = 5)
abline(h=0,col="grey")
plotMD(dgeObj,column = 6)
abline(h=0,col="grey")
plotMD(dgeObj,column = 7)
abline(h=0,col="grey")
plotMD(dgeObj,column = 8)
abline(h=0,col="grey")
```

Se observará una mayor diferencia en aquellas gráficas anteriores cuyas muestras tengan mayores factores de normalización. Para visualizar la diferencia, generaremos la gráfica para los registros de logcounts, que se han normalizado para el tamaño de la librería, pero no para el sesgo de composición y realizaremos otra gráfica para los registro de dgeObj donde podremos observar que el problema de los sesgos de composición se han solucionado.

```{r message=FALSE, fig.align='center', fig.cap="Diferencia de medias de las 4 primeras muestras muestras con datos normalizados sin ajuste y con ajuste en el sesgo de composición"}
par(mfrow=c(2,4))
plotMD(logcounts,column = 1)
abline(h=0,col="grey")
plotMD(logcounts,column = 2)
abline(h=0,col="grey")
plotMD(logcounts,column = 3)
abline(h=0,col="grey")
plotMD(logcounts,column = 4)
abline(h=0,col="grey")

plotMD(dgeObj,column = 1)
abline(h=0,col="grey")
plotMD(dgeObj,column = 2)
abline(h=0,col="grey")
plotMD(dgeObj,column = 3)
abline(h=0,col="grey")
plotMD(dgeObj,column = 4)
abline(h=0,col="grey")
```

Para reforzar lo comentado, reproduciremos de nuevo el boxplot pero esta vez con los datos normalizados y el tamaño de las librerías corregido.

```{r , message=FALSE, fig.align='center', fig.cap="Diagrama de Cajas para la distribución de los recuentos de las lecturas con Datos Normalizados"}
logcounts_norm <- cpm(dgeObj,log=TRUE)
boxplot(logcounts_norm, xlab="", ylab="Log2 cpm",las=2)
abline(h=median(logcounts_norm),col="red")
title("Boxplots de log2CPM Normalizados")
```

Podemos observar que ya existe una calidad óptima de los datos para proceder con la localización de los genes expresados diferencialmente.

# 5. Expresión Diferencial

Mediante la expresión diferencial procederemos a estudiar si existe algún tipo de asociación entre las expresiones observadas y los valores de las covariables.
Existen diferentes métodos para modelizar los datos. En mi caso he empleado el modelo lineal de limma().

## 5.1. Creación de la Matriz de Diseño

El primer paso para el análisis basado en modelos lineales es crear la matriz de diseño. Básicamente es una tabla que describe la asignación de cada muestra a un grupo o condición experimental. Tiene tantas filas como muestras y tantas columnas como grupos (si solo se considera un factor). Cada fila contiene un 1 en la columna del grupo al que pertenece la muestra y un 0 en las demás.

Como las comparaciones que nos interesan están relacionadas con el tipo de infiltración (NIT, ELI, SFI) generaremos la matriz de diseño con un único factor de 3 niveles, Group.

```{r}
library(limma)
design <- model.matrix(~ 0+Group, dgeObj$samples) 
design
```

## 5.2. Conversión de los Recuentos para modelo lineal: Voom

Tras la normalización de TMM todavía existe una relación entre la media y la varianza de los niveles de expresión del gen log cpm. Por lo tanto, utilizaremos una función llamada "voom" para calcular los pesos para cada gen y cada muestra que compensarán esta relación de varianza media en el modelo lineal.

```{r ,message=FALSE, fig.align='center', fig.cap="Voom para calcular los pesos de cada gen y cada muestra"}
v <- voom(dgeObj,design,plot = TRUE)
```

Visualizamos los resultados para las dos primeras muestras de los cinco primeros genes

```{r}
v[1:5,1:2]
```

Para chequear mejor los resultados, generaremos un boxplot de los datos sin normalizar versus los datos transformados mediante la función Voom.

```{r , message=FALSE, fig.align='center', fig.cap="Diagrama de Cajas para la distribución de los recuentos de las lecturas con Datos sin Normalizar respecto a Datos Transformados con Voom"}
par(mfrow=c(1,2))
boxplot(logcounts, xlab="", ylab="Log2 counts per million",las=2,main="logCPM no Normalizados")
abline(h=median(logcounts),col="blue")
boxplot(v$E, xlab="", ylab="Log2 counts per million",las=2,main="Voom logCPM transformados")
abline(h=median(v$E),col="blue")
```

Se oberva una mejora en la calidad de los datos donde los valores se encuentran en una escala comparable.

## 5.2.1. Estimación de la dispersión

Otra forma de convertir los recuentos es calculando la dispersión común que estima el BCV (coeficiente de variación biológica) general del conjunto de datos, promediado sobre todos los genes a través de la función estimateCommonDisp(). Esta función se encuentra incluida dentro del paquete edgeR que utiliza un método empírico de Bayes para reducir las estimaciones de dispersión genewise hacia la dispersión común.

```{r}
dgeObj_est <- estimateCommonDisp(dgeObj, verbose=TRUE)
```

como se puede ver, la salida obtenida nos proporciona el valor de la estimación de la dispersión común (Disp) y el coeficiente de variación biológica (BCV).

Para genes con bajo nivel de expresión, la dispersion común estimada supone una mayor variabilidad de la que realmente presentan, por ello es recomendable estimar la dispersión gen a gen o dispersión tagwise, donde a partir de la dispersión común y de la variabilidad real de cada gen se le asignará a cada uno de ellos una dispersión más propia de este, por lo que para calcular estas estimaciones previamente se deberá haber estimado la dispersión común.

```{r}
dgeObj_est <- estimateGLMTrendedDisp(dgeObj_est)
dgeObj_est <- estimateTagwiseDisp(dgeObj_est)
```

Tras la operativa anterior dibujaremos la gráfica de dispersión:

```{r , message=FALSE, fig.align='center', fig.cap="Gráfica de Dispersión BCV"}
plotBCV(dgeObj_est)
```

Las estimaciones de dispersión en cuanto a genes nos permiten ver una posible tendencia con un tamaño promedio de conteo.

## 5.3. Matriz de Contraste

La matriz de contrastes se usa para describir las comparaciones entre grupos. Consiste en tantas columnas como comparaciones y tantas filas como grupos. Una comparación entre grupos, llamada “contraste”, está representada por un “1” y un “-1” en las filas de grupos para comparar y ceros en el resto.

Disponemos de 3 niveles para nuestro estudio:

• Not infiltrated tissues (NIT)
• Small focal infiltrates (SFI)
• Extensive lymphoid infiltrates (ELI)

Por lo que nuestra Matriz de Contraste comparará:

* SFI-NIT
* ELI-NIT
* ELI-SFI

```{r}
cont.matrix <- makeContrasts(
  SFI_NIT= GroupSFI - GroupNIT,
  ELI_NIT= GroupELI - GroupNIT,
  ELI_SFI= GroupELI - GroupSFI,
  levels=design)
print(cont.matrix)
```

## 5.4. Estimación del modelo y Selección de Genes Expresados Diferencialmente

Una vez definida la matriz de diseño y contrastes, podemos pasar a estimar el modelo, los contrastes y realizar las pruebas de significación que nos indiquen, para cada gen y cada comparación, si puede considerarse diferencialmente expresado.

El método implementado en limma amplía el análisis tradicional utilizando modelos de Bayes empíricos para combinar la información de toda la matriz de datos y de cada gen individual y obtener estimaciones de error mejoradas. El análisis proporciona los estadísticos de test habituales como Fold-change t-moderados o p-valores ajustados, que se utilizan para ordenar los genes de más a menos diferencialmente expresados.

A fin de controlar el porcentaje de falsos positivos que puedan resultar del alto número de contrastes realizados simultáneamente, los p-valores se ajustan de forma que tengamos control sobre la tasa de falsos positivos utilizando el método de Benjamini y Hochberg.

Para realizar este paso, podemos emplear tanto el objeto de datos generado en la conversión de recuentos para modelo lineal con Voom (v) o podemos emplear el obtenido por la estimación de las dispersiones de BCV (dgeObj_est). En mi caso, emplearé el obtenido por Voom.

En primer lugar, ajustaremos el modelo lineal para cada gen.

```{r}
vfit <- lmFit(v)
vfit$coefficients[1:5,]
vfit$stdev.unscaled[1:5,]
```

A continuación se procederá a calcular las estadísticas para los contrastes de interés mediante el método de eBayes.

```{r}
vfit.cont <- contrasts.fit(vfit, cont.matrix)
vfit.cont <- eBayes(vfit.cont)
vfit.cont$coefficients[1:5,]
vfit.cont$stdev.unscaled[1:5,]
```

## 5.5. Obtención de la lista de Genes Expresados Diferencialmete

En esta sección se procederá a la realización de varias comparaciones del contraste generado para poder detectar qué genes cambian en más de una comparación. Para ello, emplearemos la función decideTests() que además realiza un ajuste de p-valores entre las comparaciones. En dicha función se invocará al ajuste FDR (False discovery rate) para múltiples contrastes. FDR se define como la proporción esperada de hipótesis nulas que son verdaderas entre las que son declaradas como significativas y han sido rechazadas erróneamente.

```{r}
summa.vfit <- decideTests(vfit.cont,adjust.method = "fdr")
```

Si visualizamos la tabla summa.vfit, nos muestra para cada gen y cada comparación un valor de 1 (si el gen esta sobre-expresado o “up” en esta condicion),
un 0 (si no hay cambio significativo) o un -1 (si esta “down”-regulado). 

```{r}
summa.vfit[1:5,]
```

Mediante el resumen podremos ver el total de genes sobre-expresados o regulados para cada comparación.

```{r}
summary(summa.vfit)
```

Mediante el diagrama de Venn podemos deducir que la diferenciación de genes se establece entre las comparaciones ELI-NIT y ELI-SFI.

```{r , message=FALSE, fig.align='center', fig.cap="Diagrama de Venn"}
library(prettyGraphs)
vennDiagram (summa.vfit[,1:3], cex=0.9, circle.col = c("turquoise", "salmon", "yellow"))
title("Genes en común entre las tres comparaciones")
```

El paquete limma implementa la función topTable() que contiene, para un contraste dado, una lista de genes ordenados desde el p-valor más pequeño al más grande que se puede considerar como más o menos expresado diferencialmente. 

Si consideramos la comparación conjunta de los 3 grupos de infiltración no obtendremos ningún gen expresado diferencialmente.

```{r}
dif.expr <- topTable(vfit.cont,coef=1,sort.by="p", adjust="fdr", n=Inf)
head(dif.expr, 20)
```

```{r}
length(which(dif.expr$adj.P.Val < 0.05))
```

```{r}
length(which(dif.expr$adj.P.Val < 0.01))
```

Si utilizamos el p-valor ajustado, obervamos que no existe nigun valor que se encuentre por debajo de 0,05 ó de 0,01 para aceptar que se encuentran diferencialmente expresados.

Como dispongo de 3 comparaciones, realizaré este paso mediante comparaciones 2 a 2 creando una tabla de resultados para cada uno de los contrastes que contendrán los genes expesados diferencialmente (topTab_SFI_NIT, topTab_ELI_NIT, topTab_ELI_SFI):

* Para la comparación SFI - NIT: Genes que cambian su expresión por el efecto de realizar pequeñas infiltraciones focales vs no realizar infiltraciones en tejidos

```{r}
topTab_SFI_NIT <- topTable(vfit.cont,number=nrow(vfit.cont), coef="SFI_NIT", adjust="fdr")
head(topTab_SFI_NIT)
```

```{r}
length(which(topTab_SFI_NIT$adj.P.Val < 0.05))
```

```{r}
length(which(topTab_SFI_NIT$adj.P.Val < 0.01))
```

* Para la comparación ELI - NIT: Genes que cambian su expresión por el efecto de realizar infiltrados linfoides extensos en tejidos vs no realizar infiltraciones en tejidos

```{r}
topTab_ELI_NIT <- topTable(vfit.cont,number=nrow(vfit.cont), coef="ELI_NIT", adjust="fdr")
head(topTab_ELI_NIT)
```

```{r}
length(which(topTab_ELI_NIT$adj.P.Val < 0.05))
```

```{r}
length(which(topTab_ELI_NIT$adj.P.Val < 0.01))
```

* Para la comparación ELI - NIT: Genes que cambian su expresión por el efecto de realizar infiltrados linfoides extensos en tejidos vs genes que cambian su expresión por el efecto de realizar pequeñas infiltraciones focales

```{r}
topTab_ELI_SFI <- topTable(vfit.cont,number=nrow(vfit.cont), coef="ELI_SFI", adjust="fdr")
head(topTab_ELI_SFI)
```

```{r}
length(which(topTab_ELI_SFI$adj.P.Val < 0.05))
```

```{r}
length(which(topTab_ELI_SFI$adj.P.Val < 0.01))
```

## 5.6. Visualización de Genes Expresados Diferencialmente

Una forma de visualizar los resultados es mediante un volcano plot, que representa en abscisas los cambios de expresión en escala logarítmica (“efecto biológico”), y en ordenadas el “menor logaritmo” del p-valor o alternativamente el estadístico.

Ejecutaremos un VolcanoPlot conjunto para las 3 comparaciones:

```{r , message=FALSE, fig.align='center', fig.cap="VolcanoPlot de los 3 tipos de Infiltración"}
volcanoplot(vfit.cont, highlight=10, main=("Genes Expresados Diferencialmente"))
abline(v=c(-1,1))
```

Con la función glXYPlot del paquete Glimma podemos generar un Volcano Plot interactivo que nos permite visualizar con detalle los resultados para cada una de las muestras:

```{r}
library(Glimma)
glXYPlot(x=vfit.cont$coefficients[,1], y=vfit.cont$lods[,1],
         xlab="logFC", ylab="B", main="Volcano plot",
         counts=dgeObj$counts, groups=dgeObj$samples$Group, status=summa.vfit[,1], folder="./results/volcano")
```

Para obtener un mayor detalle, procederé a generar un Volcano Plot por cada comparación:

```{r , message=FALSE, fig.align='center', fig.cap="VolcanoPlot de la comparación SFI - NIT"}
volcanoplot(vfit.cont, coef="SFI_NIT", style = "B-statistic", highlight=10, main=paste("Genes Expresados Diferencialmente", colnames(cont.matrix)[1], sep="\n"))
abline(v=c(-1,1))
```

```{r , message=FALSE, fig.align='center', fig.cap="VolcanoPlot de la comparación ELI - NIT"}
volcanoplot(vfit.cont, coef="ELI_NIT", style = "B-statistic", highlight=10, main=paste("Genes Expresados Diferencialmente", colnames(cont.matrix)[2], sep="\n"))
abline(v=c(-1,1))
```

```{r , message=FALSE, fig.align='center', fig.cap="VolcanoPlot de la comparativa ELI -SFI"}
volcanoplot(vfit.cont, coef="ELI_SFI", style = "B-statistic", highlight=10, main=paste("Genes Expresados Diferencialmente", colnames(cont.matrix)[3], sep="\n"))
abline(v=c(-1,1))
```

Los genes cuyo log odds es superior a 0 y cuyo log2 fold change es, en valor absoluto, superior a 1, son candidatos a estar diferencialmente expresados.

Si consideraramos genes expresados diferencialmente aquellos que tienen un p-valor ajustado inferior a 0.05 o 0.01, el numero de genes diferencialmente expresado en cada caso seria:

```{r echo=FALSE}
cat("Numero de genes con un p-valor inferior a 0.05:\n")
  cat ("SFI vs NIT:",sum(topTab_SFI_NIT$adj.P.Val<=0.05),"\n")
  cat ("ELI vs NIT: ", sum(topTab_ELI_NIT$adj.P.Val<=0.05),"\n")
  cat ("ELI vs SFI: ", sum(topTab_ELI_SFI$adj.P.Val<=0.05),"\n")  

cat("\nNumero de genes con un p-valor inferior a 0.01:\n")
  cat ("SFI vs NIT: ", sum(topTab_SFI_NIT$adj.P.Val<=0.01),"\n")
  cat ("ELI vs NIT: ", sum(topTab_ELI_NIT$adj.P.Val<=0.01),"\n")
  cat ("ELI vs SFI: ", sum(topTab_ELI_SFI$adj.P.Val<=0.01),"\n")  
```

Por lo tanto,no se aprecian genes expresados diferencialmente en la comparativa SFI - NIT, pero sí se aprecian genes expresados diferencialmente en la comparativa ELI - NIT- (Visualizamos los 5 primeros registros):

```{r}
topTab_ELI_NIT [1:5,]
```

y en la comparativa ELI - SFI. (Visualizamos los 5 primeros registros):

```{r}
topTab_ELI_SFI[1:5,]
```

## 5.7. Exploración de los resultados de Genes Expresados Diferencialmente

Podemos especificar un cambio mínimo de log-fold con la función "tratar" en lugar de usar "eBayes" para ajustar la magnitud del tamaño del efecto. Por ello, aplicaremos una nueva restricción en el cual log-fold-changes (log-FCs) que esté por encima de uno. Un log-FC que sea significativamente mayor que 1 es equivalente a una diferencia de 2 veces entre los tipos de infiltración.

```{r}
vfit.treat <- treat(vfit.cont,lfc=1)
res.treat <- decideTests(vfit.treat,adjust.method = "fdr")
summary(res.treat)
```

Este método es mucho más restrictivo que el empleado anteriormente, por ello existe una diferencia tan grande en relación al número de genes sobre-expresados y down-regulados 

Volvemos a ejecutar la función topTable() para todas las comparaciones:

* Comparación conjunta de los 3 grupos de infiltración:

```{r}
dif.expr2 <- topTable(vfit.treat,coef=1,sort.by="p", adjust="fdr",n=Inf)
head(dif.expr2)
```

```{r}
length(which(dif.expr2$adj.P.Val < 0.05))
```

```{r}
length(which(dif.expr2$adj.P.Val < 0.01))
```

* Para la comparación SFI - NIT:

```{r}
topTab_SFI_NIT_treat <- topTable(vfit.treat,number=nrow(vfit.treat), coef="SFI_NIT", sort.by="p", adjust="fdr")
head(topTab_SFI_NIT_treat)
```

* Para la comparación ELI - NIT:

```{r}
topTab_ELI_NIT_treat <- topTable(vfit.treat,number=nrow(vfit.treat), coef="ELI_NIT", sort.by="p", adjust="fdr")
head(topTab_ELI_NIT_treat)
```

* Para la comparación ELI - SFI:

```{r}
topTab_ELI_SFI_treat <- topTable(vfit.treat,number=nrow(vfit.treat), coef="ELI_SFI", sort.by="p", adjust="fdr")
head(topTab_ELI_SFI_treat)
```

```{r echo=FALSE}
cat("Numero de genes con un p-valor inferior a 0.05:\n")
  cat ("SFI vs NIT:",sum(topTab_SFI_NIT_treat$adj.P.Val<=0.05),"\n")
  cat ("ELI vs NIT: ", sum(topTab_ELI_NIT_treat$adj.P.Val<=0.05),"\n")
  cat ("ELI vs SFI: ", sum(topTab_ELI_SFI_treat$adj.P.Val<=0.05),"\n")  

cat("\nNumero de genes con un p-valor inferior a 0.01:\n")
  cat ("SFI vs NIT: ", sum(topTab_SFI_NIT_treat$adj.P.Val<=0.01),"\n")
  cat ("ELI vs NIT: ", sum(topTab_ELI_NIT_treat$adj.P.Val<=0.01),"\n")
  cat ("ELI vs SFI: ", sum(topTab_ELI_SFI_treat$adj.P.Val<=0.01),"\n")  
```

Con la función glXYPlot del paquete Glimma generaremos el Volcano Plot interactivo que nos permite visualizar con detalle los resultados para cada una de las muestras:

```{r}
library(Glimma)
glMDPlot(vfit.treat, coef=1, counts=dgeObj$counts, groups=dgeObj$samples$Group,
        status=res.treat, side.main="ENTREZID", main="Plot md",
        folder="./results/md")
```

El diagrama de Venn permite visualizar cuántos de estos genes son compartidos por una o más selecciones sin diferenciar entre genes up o down regulados.

```{r , message=FALSE, fig.align='center', fig.cap="Diagrama de Venn tras ajuste Log-FC"}
vennDiagram (res.treat[,1:3], cex=0.9, circle.col = c("turquoise", "salmon", "yellow"))
title("Genes en común entre las tres comparaciones")
```

Mediante la tabla anterior podemos deducir que la diferenciación de genes se establece solo en la comparación ELI-NIT.

Como este paso es demasiado restrictivo, emplearemos los datos obtenidos del método de eBayes para ajustar la magnitud del tamaño del efecto en lugar de log-fold por lo que continuaré mi análisis con vfit.cont en lugar de vfit.treat.  

## 5.7.1. Mapa de Calor Datos Normalizados

Volveremos a generar el mapa de calor, pero esta vez con los datos normalizados para examinar de nuevo la agrupación jerárquica de las muestras. Para ello, seleccionaremos de nuevo los 500 genes más variables.

```{r , message=FALSE, fig.align='center', fig.cap="Mapa de Calor de los 500 genes más variables con los Datos Normalizados"}
library(gplots)
var_genes_norm <- apply(dgeObj$counts, 1, var)
select_var_norm <- names(sort(var_genes_norm, decreasing=TRUE))[1:500]
highly_variable_lcpm_norm <- logcounts[select_var_norm,] # Seleccionar los genes

mypalette <- brewer.pal(11,"Spectral")
morecols <- colorRampPalette(mypalette)
col.group <- c("green","purple","orange")[dgeObj$samples$Group]
heatmap.2(highly_variable_lcpm_norm,
          col=rev(morecols(50)),
          trace="column", 
          main="500 genes más variables",
          ColSideColors=col.group,scale="row")
```

En contraste con el mapa de calor generado entre los datos sin normalizar y los datos normalizados, podemos ver que en este último caso, una mayor agrupación de las muestras y los genes. Si atendemos al histograma, se obtiene una distribución normal de las mismas.

# 6. Anotación de Genes

En el proceso de “anotación” buscaremos información para asociar los identificadores que aparecen en las tablas superiores, correspondientes a códigos Ensembl con nombres más familiares como el Identificador del gen Entrez o la descripción del gen. Para agregar las anotaciones utilizaremos el paquete org.Hs.eg.db correspondiente a las anotaciones del genoma humano, basada principalmente en el mapeo utilizando identificadores de genes de Entrez.

```{r}
library(org.Hs.eg.db)
columns(org.Hs.eg.db)
```

Mediante la librería grex podremos convertir los identificadores de genes 'Ensembl' de los datos de Expresión de tejido genotipo (GTEx) en identificadores en otros sistemas de anotación, incluidos 'Entrez', 'HGNC' y 'UniProt'.

Realizaremos las anotaciones sobre cada tipo de comparación como hemos hecho a lo largo de todo nuestro estudio:

* Anotaciones para la comparación conjunta de los 3 grupos de infiltración:

```{r}
library(grex)
id_vfit = rownames(vfit.cont)
df_vfit = grex(id_vfit)
vfit.cont$genes <- df_vfit[,c("ensembl_id","entrez_id","hgnc_symbol", "hgnc_name")]
names(vfit.cont$genes) <- c("ENSEMBL","ENTREZID","SYMBOL","GENENAME")
head(vfit.cont$genes)
```

* Anotaciones para la comparación SFI-NIT:

```{r}
library(grex)
id_SFI_NIT = rownames(topTab_SFI_NIT)
df_SFI_NIT = grex(id_SFI_NIT)
topTab_SFI_NIT$genes <- df_SFI_NIT[,c("ensembl_id","entrez_id","hgnc_symbol", "hgnc_name")]
names(topTab_SFI_NIT$genes) <- c("ENSEMBL","ENTREZID","SYMBOL","GENENAME")
head(topTab_SFI_NIT$genes)
```

A tener en cuenta que he ejecutado las anotaciones tanto de la comparación conjunta de los 3 tipos de infiltración, como de la comparación SFI-NIT pero ninguna de ellas disponía de ningún gen expresado diferencialmente como concluímos en los pasos anteriores de nuestro análisis.

* Anotaciones para la comparación ELI-NIT: 

```{r}
library(grex)
id_ELI_NIT = rownames(topTab_ELI_NIT)
df_ELI_NIT = grex(id_ELI_NIT)
topTab_ELI_NIT$genes <- df_ELI_NIT[,c("ensembl_id","entrez_id","hgnc_symbol", "hgnc_name")]
names(topTab_ELI_NIT$genes) <- c("ENSEMBL","ENTREZID","SYMBOL","GENENAME")
head(topTab_ELI_NIT$genes)
```

```{r}
library(grex)
id_ELI_SFI = rownames(topTab_ELI_SFI)
df_ELI_SFI = grex(id_ELI_SFI)
topTab_ELI_SFI$genes <- df_ELI_SFI[,c("ensembl_id","entrez_id","hgnc_symbol", "hgnc_name")]
names(topTab_ELI_SFI$genes) <- c("ENSEMBL","ENTREZID","SYMBOL","GENENAME")
head(topTab_ELI_SFI$genes)
```

Debemos tener en cuenta que si se desconoce esta información, el vector contendrá un NA.

Solo con ver las 5 primeras anotaciones de los grupos, ya se pueden observar que existe anotaciones en común entre las comparaciones ELI-NIT y ELI-SFI.

# 7. Análisis de la Significación Biológica

El Análisis de Significación Biológica busca establecer si, dada una lista de genes seleccionados por ser diferencial expresada entre dos condiciones, las funciones, procesos biológicos o vías moleculares que los caracterizan aparecen en esta lista con más frecuencia que entre el resto de los genes analizados.

```{r}
library(org.Hs.eg.db)
library("AnnotationDbi")
columns(org.Hs.eg.db)
```

Ejecutaremos las anotaciones para cada una de las comparaciones establecidas:

```{r}
go_SFI_NIT <- goana(vfit.cont, coef="SFI_NIT",species = "Hs",geneid = "ENTREZID")
topGO(go_SFI_NIT, n=10)
```

```{r}
go_ELI_NIT <- goana(vfit.cont, coef="ELI_NIT",species = "Hs",geneid = "ENTREZID")
topGO(go_ELI_NIT, n=10)
```

```{r}
go_ELI_SFI <- goana(vfit.cont, coef="ELI_SFI",species = "Hs",geneid = "ENTREZID")
topGO(go_ELI_SFI, n=10)
```

En nuestro estudio de comparación, tanto en el caso de ELI-NIT como en ELI-SFI se ha encontrado una vía destacable relacionada con la respuesta inmune y sistemas de procesos inmunes en ambos casos.

# 8. Resumen de Resultados y Discusión

Mediante el *preprocesado* realizado en la fase de Exploración y Control de Calidad hemos detectado la necesidad de ajustar nuestros datos para poder disponer de un análisis más acertado y poder obtener conclusiones más fiables del mismo. 

Los *datos normalizados y filtrados* nos han permitido detectar una serie de genes diferencialmente expresados con los que hemos procedido a realizar los estudios de significación biologica.

En el estudio que he seleccionado, así como las comparaciones establecidas para el mismo, solo existen genes expresados diferencialmente en 2 de las 3 comparaciones establecidas (ELI-NIT y ELI-SFI) si tomamos los valores del p-valor ajustado. Al mismo tiempo, hemos empleado diferentes métodos para ajustar al máximo posible nuestros datos. Sin embargo, hemos tenido que descartar alguno de los mismos por ser demasiados restrictivos, lo que nos iba a hacer perder demasiada información, como ha sido el caso del ajuste de la magnitud del tamaño del efecto por medio de log-fold. Por lo que en el caso de mi estudio, no tiene mucho sentido realizar un *Análisis de Significación Biológica* teniendo en cuenta este aspecto y por este motivo, fue necesario basé mi estudio ajustando la magnitud del tamaño del efecto por medio de eBayes.

Tras la realización de dichos análisis, se puede llegar a la *conclusión* que parece existir una relación entre un tipo de infiltración (ELI) asociada a una respuesta inmune del organismo.

Los archivos generados durante el análisis han sido los siguientes:

```{r listOfFiles, echo=FALSE}
listOfFiles <- dir("./results/") 
knitr::kable(
  listOfFiles, booktabs = TRUE,
  caption = 'Listado de Ficheros generados durante el Análisis',
  col.names="Listado de Ficheros"
)
```

## 8.1. Discusión

En relación al estudio realizado podemos destacar los siguientes puntos:

- El número de muestra utilizadas para el estudio es demasiado pequeña, por lo que se puede generar un mayor número de errores, más falsos negativos y problemas en la interpretación de los resultados. 
- Los métodos empleados se encuentran acordes a los diferentes casos que se nos han planteado en la asignatura. Probablemente existan métodos que se ajusten mucho mejor al estudio que queremos realizar y que sabremos aplicar a medida que vayamos adquiriendo conocimientos y experiencia en el Análisis de Datos Ómicos.

# 9. Bibliografía

- Obtención de los datos en la Base de Datos  GTEx (Genotype-Tissue Expression): (<https://www.gtexportal.org/home/>) 
- Diferential Expression Analysis using edgeR, Oscar Rueda & Bernard Pereira (2015): (<https://dokumen.tips/documents/differential-expression-analysis-using-edger-github-pages-di-erential-expression.html>)
- Página de Bioconductor para la localización de los paquetes necesarios para el análisis: (<https://www.bioconductor.org/install/>)
- Página de apoyo y soporte en la resolución de errores obtenidos durante el análisis: (<https://www.biostars.org/>)
- Técnicas de Análisis de Expresión diferencial basadas en conceptos para el estudio de datos RNA-seq usando R y Bioconductor, Sara Carrasco (2015): (<https://idus.us.es/bitstream/handle/11441/40563/Carrasco%20Carrasco%20Sara%20TFG.pdf?sequence=1&isAllowed=y>)
- RNA_seq_tutorial, Lauren Blake (2018): (<https://rpubs.com/laurenblake/384967>)
- Statistical analysis of RNA-Seq data, Ignacio González (2014): (<http://www.nathalievialaneix.eu/doc/pdf/tutorial-rnaseq.pdf>)
- RNAseq analysis in R: (<https://bioinformatics-core-shared-training.github.io/RNAseq-R/>)
- Analyzing RNA-seq data with DESeq2, Michael I. Love, Simon Anders, and Wolfgang Huber (2020): (<http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html>)
- Bioinformática Estadística - Análisis de Datos Ómicos, Guillermo Ayala (2020): (<https://www.uv.es/ayala/docencia/tami/tami13.pdf>)
- RNAseq pipeline - Bioconductor, Ricardo Gonzalo Sanz y Alex Sánchez-Pla (2020): (<https://github.com/ASPteaching/Omics_data_analysis-Case_study_2-RNA-seq>)
- Repositorio GitHub: (<https://github.com/>)
- Guía para el uso de RMarkdown: (<https://bookdown.org/gboccardo/manual-ED-UCH/introduccion-al-uso-de-rmarkdown-para-la-compilacion-de-resultados-de-rstudio-en-diferentes-formatos.html>)
